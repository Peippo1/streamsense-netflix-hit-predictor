{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69f23350-00a4-4da0-a40f-8f3a6f127417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean and standardise column names\n",
    "We want consistent, lower_snake_case column names across the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8a3e86f-595c-4b89-a3d3-6d446bd676f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# âš™ï¸ 02 â€“ Feature Engineering & Label Definition\n",
    "\n",
    "**Objective:**  \n",
    "Transform the ingested Netflix dataset into a clean, structured, and model-ready format by standardising column names, deriving new features, and defining the target label (`is_hit`).\n",
    "\n",
    "**Scope of this notebook:**\n",
    "- Load the raw data from the Delta table **`netflix_raw`** created in Notebook 01  \n",
    "- Standardise all column names to `snake_case` for consistency  \n",
    "- Parse and transform key fields:\n",
    "  - Extract `release_year` from `release_date`\n",
    "  - Derive numeric `duration_num` from `duration`\n",
    "  - Add a binary flag `is_movie` based on category  \n",
    "- Handle missing or null values where appropriate  \n",
    "- Define a preliminary target label `is_hit` to support downstream modelling  \n",
    "- Save the cleaned, feature-rich dataset as **`netflix_clean`** (or **`netflix_model_data`**) for use in Notebook 03\n",
    "\n",
    "**Outcome:**  \n",
    "A fully prepared dataset suitable for exploratory modelling, feature selection, and predictive analysis within Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b54d235-47cd-4689-bf3a-633050194b95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_raw = spark.table(\"netflix_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "797a3426-32be-4980-be06-84904cc4dcb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def to_snake_case(name):\n",
    "    name = re.sub(r'[^0-9a-zA-Z]+', '_', name)\n",
    "    name = re.sub(r'([a-z0-9])([A-Z])', r'\\1_\\2', name)\n",
    "    return name.lower().strip('_')\n",
    "\n",
    "df_clean = df_raw.select([F.col(c).alias(to_snake_case(c)) for c in df_raw.columns])\n",
    "\n",
    "display(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a181bed-4baa-4b72-90a4-01dd2aa40241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_raw.select([F.col(c).alias(to_snake_case(c)) for c in df_raw.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "637b7928-c8a0-459d-b4e2-458386e298f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clean = (\n",
    "    df_clean\n",
    "    .withColumn(\"release_year\", F.year(F.to_date(\"release_date\", \"MMMM d, yyyy\")))\n",
    "    .withColumn(\"duration_num\", F.regexp_extract(\"duration\", r\"(\\d+)\", 1).cast(\"int\"))\n",
    "    .withColumn(\"is_movie\", F.when(F.lower(\"category\") == \"movie\", 1).otherwise(0))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95f036d9-4fb0-4741-a2a0-b27bf2072ea8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Parse and clean key fields\n",
    "Extract the release year and normalise the duration field (minutes vs seasons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5779451-e1c2-407d-9e01-e3a32753e371",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_clean = (\n",
    "    df_clean\n",
    "    # Extract year from release_date (handles â€œSeptember 9, 2019â€ format)\n",
    "    .withColumn(\"release_year\", F.year(F.to_date(F.col(\"release_date\"), \"MMMM d, yyyy\")))\n",
    "    # Extract numeric duration (e.g. â€œ90 minâ€ â†’ 90, â€œ2 Seasonsâ€ â†’ 2)\n",
    "    .withColumn(\n",
    "        \"duration_num\",\n",
    "        F.regexp_extract(F.col(\"duration\"), r\"(\\d+)\", 1).cast(\"int\")\n",
    "    )\n",
    "    # Label whether itâ€™s a Movie or TV Show\n",
    "    .withColumn(\n",
    "        \"is_movie\",\n",
    "        F.when(F.lower(F.col(\"category\")) == \"movie\", 1).otherwise(0)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00a25510-4a2b-4642-8e12-76e3aef7e3e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Define a basic â€œhitâ€ label (is_hit)\n",
    "The dataset doesnâ€™t have view counts or IMDb scores, so letâ€™s create a proxy â€œpopularityâ€ label using the text length of the description â€” purely for demonstration. Later, if we merge external IMDb data, weâ€™ll replace it with real metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8384631-c5b1-44fc-a89e-ff1081f1affc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Heuristic hit label based on description length (as a placeholder)\n",
    "df_clean = df_clean.withColumn(\n",
    "    \"is_hit\",\n",
    "    F.when(F.length(F.col(\"description\")) > 120, 1).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bc9e699-7322-4a84-84a0-499bd8107d64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save as a Delta table\n",
    "This becomes our modelling dataset for the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa5d5534-a1f4-4b99-bff7-3e406bac647f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_clean.write\n",
    "    .mode(\"overwrite\")\n",
    "    .format(\"delta\")\n",
    "    .saveAsTable(\"netflix_clean\")\n",
    ")\n",
    "\n",
    "print(\"Saved table: netflix_clean\")\n",
    "\n",
    "# Quick preview\n",
    "display(spark.table(\"netflix_clean\").select(\"title\", \"category\", \"release_year\", \"duration_num\", \"is_hit\").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fde61e4e-24a1-48f6-8b81-09e2d2b52374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ§¾ Notebook Summary â€“ 02_Feature_Engineering_And_Label\n",
    "\n",
    "**Objective:**  \n",
    "Transform the raw Netflix dataset (`netflix_raw`) into a clean, feature-rich, and model-ready format for machine learning.\n",
    "\n",
    "**Key steps completed:**\n",
    "- Loaded data from the ingested Delta table **`netflix_raw`**\n",
    "- Standardised all column names to `snake_case` using a reusable Python function  \n",
    "- Parsed and engineered key fields:\n",
    "  - Extracted `release_year` from `release_date`\n",
    "  - Converted `duration` to numeric `duration_num`\n",
    "  - Added binary flag `is_movie` for category type\n",
    "- Created a preliminary `is_hit` label (placeholder for future popularity metric integration)\n",
    "- Persisted the transformed dataset as a managed Delta table: **`netflix_clean`**\n",
    "\n",
    "**Findings:**\n",
    "- The dataset is now structured and ready for feature selection and modelling\n",
    "- Most categorical features (`rating`, `category`, `country`) contain useful variance for prediction\n",
    "- Nulls remain in descriptive fields (e.g., `director`, `cast`) but do not block training\n",
    "\n",
    "**Next steps:**\n",
    "- Proceed to **`03_modelling_and_evaluation`** to:\n",
    "  - Train a baseline classifier (e.g., Random Forest)\n",
    "  - Evaluate model performance using ROC-AUC, precision, and recall\n",
    "  - Track experiments in MLflow\n",
    "  - Generate insights and feature importance visualisations"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_feature_engineering_and_label",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
